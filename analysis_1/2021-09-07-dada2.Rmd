---
title: "dada2 analysis for blue-jam project"
author: "jen nguyen"
date: "9/7/2021"
output: html_notebook
---

```{r}
library(dada2); packageVersion("dada2")
library(ggplot2)
library(here)
library(phyloseq)
library(Biostrings)
library(tidyverse)
library(fs)
```

```{r}
path_raw <- here::here("data/reads/raw")
path_filtered <- here::here("data/reads/filtered")
list.files(path_raw)
```

```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(path_raw, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path_raw, pattern="_R2_001.fastq", full.names = TRUE))
fnFs %>% path_file %>% head
```

```{r}
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
print(sample.names)
```

```{r}
plotQualityProfile(fnFs[1:2]) +
  geom_vline(xintercept = 200) # truncation length of forward reads
```
```{r}
plotQualityProfile(fnRs[1:2]) +
  geom_vline(xintercept = 150) # truncation length of reverse reads
```
```{r}
plotQualityProfile(tail(fnRs,2)) +
  geom_vline(xintercept = 150) # truncation length of reverse reads
```

```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path_filtered, paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path_filtered, paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```

```{r, eval=FALSE}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(248,225),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```
```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(200,150),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

More filtered reads by truncating raw reads by more bp!
We are only sequencing V4 in this data.

```{r}
# Learn the Error Rates
errF <- learnErrors(filtFs, multithread=TRUE)
```
```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```


```{r}
plotErrors(errF, nominalQ=TRUE)
```
Wisdoms from Mike:
DADA2 uses our own data (dots) to calculate error rates (model = black line).
Sometimes the expected error based on the nominal definition of Q-score (red line) matches
error seen in our data. But often, we have a higher error rate and DADA2 will use this.

More sequencing data is more info for the model.
A good fit between model and observed data (black line and dots) means
We now have good understanding of error rates in our data!

```{r}
# Sample Inference
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
```

```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
```

```{r}
dadaFs[[1]]
```

Notes from DADA2 tutorial:
The DADA2 algorithm inferred 183 true sequence variants from the 2874 unique sequences in the first sample. There is much more to the dada-class return object than this (see help("dada-class") for some info), including multiple diagnostics about the quality of each denoised sequence variant, but that is beyond the scope of an introductory tutorial.

```{r}
# Merge Paired Reads
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```

```{r}
# Construct Sequence Table
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
This table contains 410 ASVs!

```{r}
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```
253 bp nicely matches the expected length of V4 region of 16S rRNA.
In this run, Gut4Health used an in-house library prep protocol that amplified the V4 region.
Next run with these same DNA samples will be a commercial kit that amplifies V3V4.

```{r}
# Remove Chimeras
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```

```{r}
# Calculate Fraction of Reads that were Chimeras
sum(seqtab.nochim)/sum(seqtab)
```
Chimeras make up a substantial portion (~15%) of merged sequence variants, but are only about 1% of the merge sequenced reads when accounting for the abundance of these variants.

```{r}
# Track Reads Through the Pipeline
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
write.csv(track, here::here('output', 'dada2', 'track.csv'))
```
* Wisdoms from Mike *
Some of the lower read count samples are losing lots of reads in the filtering step.
We can avoid some loss in various ways, including trimming more to remove noisier overlap.
This increased trimming/truncation is especially possible with shorter reads (V4 vs V3V4).


```{r}
# getting the right name for our taxonomy database files
here('data', 'database') %>% list.files()
```


```{r}
# Assign Taxonomy using the training set
taxa <- assignTaxonomy(
  seqtab.nochim, 
  here("data", "database", "silva_nr99_v138.1_train_set.fa.gz"),
  multithread=TRUE
)
```

```{r}
# Add species
taxa <- addSpecies(
  taxa, 
  here("data", "database", "silva_species_assignment_v138.1.fa.gz"),
  allowMultiple = TRUE
)
```

```{r}
# Inspect taxonomic assignments
taxa.print <- taxa # Removing sequence row names for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```

```{r}
# Evaluate Accuracy 
unqs.mock <- seqtab.nochim["mock-",]
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE) # Drop ASVs absent in the Mock
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")
```
The ZymoBIOMICS Gut Microbiome Standard has 21 species!
Less truncation gave 21 ASVs in Mock Community whereas more truncation gives 29!

```{r}
# Evaluate Accuracy 
unqs.mock <- seqtab.nochim["mock-2",]
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE) # Drop ASVs absent in the Mock
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")
```

Hm, how to interpret this?

More ASVs than species in the mock community can arise by having multiple 16S sequences per species. This is something to check from the sequences available from the mock communities.

More ASVs can also arise via contamination. If there is a sequence in the mock as well as in the samples, then this is good evidence of contamination.

```{r, eval = FALSE}
mock.ref <- getSequences(file.path(path, "HMP_MOCK.v35.fasta"))
match.ref <- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))
cat("Of those,", sum(match.ref), "were exact matches to the expected reference sequences.\n")
```

Skipped checking that mock community sequences were exact matches to expected reference sequences because the files associated with our community are currently available in a different format.

```{r}
# Saving DADA2 output
saveRDS(seqtab.nochim,file=here("output","dada2","seqtable_nochimeras.rds"))
saveRDS(seqtab,file=here("output","dada2","seqtable.rds"))
saveRDS(taxa,file=here("output","dada2","taxonomic_assignments.rds"))
```


```{r}
sessionInfo()
```

